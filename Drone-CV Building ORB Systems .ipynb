{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Drone_CV Building ORB Systems</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-dc3f73838a02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing these two are standard practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('../vid/swarm_drone/swarm_drone.mp4')\n",
    "ret,frame = cap.read()\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VideoCapture puts a video into cv2.\n",
    "\n",
    ".read reads the object and returns True if the object has been read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(func, link='../vid/swarm_drone/swarm_drone.mp4'):\n",
    "    cap = cv2.VideoCapture(link)\n",
    "    while True:\n",
    "         # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        func(ret, frame)\n",
    "        if cv2.waitKey(1) & 0xff == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def func(ret, frame):\n",
    "    cv2.imshow('frame' ,frame)\n",
    "run(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"run\" will take in a function and a link.\n",
    "\n",
    "We will first VideoCapture the link as we did in the prev. cell.\n",
    "\n",
    "We want for CV to read this object (view) until we press the 27 key, \n",
    "    which closes the window that is displaying this video/object. \n",
    "    \n",
    "Very inefficeint. Basically what func does is that it displays the video using imshow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(frame, factor=1):\n",
    "    if factor == 1:\n",
    "        return frame\n",
    "    height, wid = frame.shape[:2]\n",
    "    scaled_wid, scaled_height = np.int(wid * factor), np.int(height * factor)\n",
    "    frame = cv2.resize(frame, (scaled_wid, scaled_height))\n",
    "    return frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Scale' will rescale the video. It will take in a frame, if the frame has a factor of 1 nothing will happen. However, if not, then we will get the current height and width of the frame by taking the first two elements of the shape list output, we will rescale and reassign (resize) the frame with the new dimensions. And then return the new frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orb_func(ret, frame):\n",
    "    frame = scale(frame)\n",
    "    orb = cv2.ORB_create()\n",
    "    kp = orb.detect(frame)\n",
    "    # kp, des = orb.compute(frame, kp)\n",
    "    kp_drawn = cv2.drawKeypoints(frame, kp, None, color=(0, 255, 0))\n",
    "    cv2.imshow('kp_drawn', kp_drawn)\n",
    "run(orb_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(0) Idk why we even need the parameter for ret. \n",
    "\n",
    "(1) Rescale the frame.\n",
    "\n",
    "(2) cv2.ORB_create will initiate ORB detectors. \n",
    "\n",
    "(3) orb.detect(frame) will look for keypoints with ORB in our frame.\n",
    "\n",
    "(4) After detecting the orbs, we will draw green points for the orbs using drawKeyPoints.\n",
    "\n",
    "(5) We use imshow to display the current frame with the green keypoints on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orb_kp(frame, orb=cv2.ORB_create()):\n",
    "    frame = scale(frame)\n",
    "    kp = orb.detect(frame)\n",
    "    kp_drawn = cv2.drawKeypoints(frame, kp, None, color=(0, 255, 0))\n",
    "    return kp, kp_drawn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Parameters: the frame, and initiate ORB detectors.\n",
    "\n",
    "(2) We will rescale the frame.\n",
    "\n",
    "(3) We will keypoints with ORBs in the frame.\n",
    "\n",
    "(4) We will color keypoints green.\n",
    "\n",
    "(5) This time we wil return te value returned after \"detect\"ing for orbs in the frame and the frame with \"KeyPoints.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kp_to_pairs(kp, dim):\n",
    "    max_y, max_x, _ = dim\n",
    "    out = np.zeros((len(kp), 2))\n",
    "    for i in range(len(kp)):\n",
    "        x, y = kp[i].pt\n",
    "        \n",
    "        out[i] = np.array([x, max_y-y])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) For our paramters, we will take the list of key points (from the previous cell)the key points retruend from running orb.detect(frame). And we will take dimensions. \n",
    "\n",
    "(2) We will break up the dimensions from the parameter in three variables - max_y, max_x, _.\n",
    "\n",
    "(3) We will create a matrix of 0's with height: len(kp) and width: 2.\n",
    "\n",
    "(4) We will loop through the matrix and recrod the coordinate of each keypoint?\n",
    "\n",
    "(5) We will edit the matrix with new keypoint values?\n",
    "\n",
    "(6) We return a matrix with 1's where there are keypoints and 0's where there aren't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centers(Z, num=10):\n",
    "    # convert to np.float32\n",
    "    Z = np.float32(Z)\n",
    "    # define criteria and apply kmeans()\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    ret,label,center=cv2.kmeans(Z,num,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "    return center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Parameters: Z, num = 10.\n",
    "\n",
    "(2) Convert Z to np.float32\n",
    "\n",
    "(3) We will set up our criteria, which is bascially an iteration terminator criteria.When condition is satisfied, the algorithm iteration stops. It takes in \n",
    "(a) type of algorithm:\n",
    "TERM_CRITERIA_EPS (stop algorithm iteration if epsilon is reached) \n",
    "TERM_CRITERIA_MAX_ITER (stop algorithm after specified number of iterations)\n",
    "COMBINATION of EPS and MAX_ITER (stops algorithm if EITHER is true.\n",
    "(b) max_iter (max number of iteration) \n",
    "(c) episilon (required accuracy)\n",
    "\n",
    "(4) Parameters: samples of np.float32 datatype, nclusters(K) number of clusters, criteria for stopping iteration algorithm, number of attempts, type of how cluster centers should be chosen.\n",
    "Return: density of summation of distance to center, array of label, array of centers of clusters.\n",
    "\n",
    "(5) We return just the array of centers of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxes(frame, name, centers, dim):\n",
    "    y_max, x_max, _  = dim\n",
    "    \n",
    "    for i in range(len(centers)):\n",
    "        x, y = centers[i]\n",
    "        x, y = np.int(x), np.int(y_max - y)\n",
    "        half_size = 50\n",
    "        top_left = x - half_size, y - half_size\n",
    "        bot_right = x + half_size, y + half_size\n",
    "        frame = cv2.rectangle(frame, top_left, bot_right, (0, 255, 0),  1)\n",
    "        # frame = cv2.circle(frame, (x, y), 50, (0, 255, 0),  1)\n",
    "    cv2.imshow(name, frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Parameters: frame, name, array of centers, dimensions\n",
    "\n",
    "(2) We will split up the dimension into axes.\n",
    "\n",
    "(3) Loop through each center, and create a rectangle surrounding each center of some dimension.\n",
    "\n",
    "(4) Will display the frame with a rectangle around each center. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d23b42c5dabc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplot_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'frame'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morb_func_boxed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'run' is not defined"
     ]
    }
   ],
   "source": [
    "def orb_func_boxed(ret, frame):\n",
    "    kp, frame = get_orb_kp(frame, orb=cv2.ORB_create(nfeatures=1000))\n",
    "    dim = frame.shape\n",
    "    Z = kp_to_pairs(kp, dim)\n",
    "    centers = get_centers(Z, num=15)\n",
    "    plot_boxes(frame, 'frame', centers, dim)\n",
    "    \n",
    "run(orb_func_boxed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) get_orb_kp will assign kp to an array of keypoints and frame to a frame with green keypoints.\n",
    "\n",
    "(2) we assign shape of frame to dim: height, width, channel\n",
    "\n",
    "(3) Z will be the edited matrix with keypoints? So the points with keypoints will be 1's. Else will be 0's.\n",
    "\n",
    "(4) We will get an array of centers from the matrix Z.\n",
    "\n",
    "(5) Will display the frame with rectangle around each center. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Template Matching</b>\n",
    "\n",
    "Searching for similar pattern between two images. \n",
    "\n",
    "Uses a template image and slides it along the horizontal and vertical axis of the frame image and looks for template matches.\n",
    "\n",
    "As it slides, we get a gray scale image that displays white when there is a template match and black if else.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-39502cf510a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtemplate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'template.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'players.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "template = cv2. imread('template.jpg', 0)\n",
    "frame = cv2.imread('players.jpg',0)\n",
    "\n",
    "cv2.imshow(\"Frame\", frame)\n",
    "cv2.imshow(\"Template\", template)\n",
    "\n",
    "result = cv2.matchTemplate(frame, template, cv2.TM_CCOEFF_NORMED)\n",
    "# TM_CCOEFF_NORMED is one in many different ways of template matching.\n",
    "\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "print(max_val,max_loc)\n",
    "cv2.circle(result, max_loc, 15, 255, 2)\n",
    "# Recall that the color white has the greatest value.\n",
    "# .minMaxLoc returns the location and values of the max value and the min value.\n",
    "# We can visualize this by drawing a circle onto the frame:\n",
    "# parameters: frame, max_loc, radius, color of circle, line thickness\n",
    "\n",
    "cv2.imshow(\"Matching\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destoryAllWindows()\n",
    "#Three windows: Template, Frame, and Matched Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Haar Cascade Method </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Trains a classifier by feeding it images with labels (positive and negative.) Ex. images that have faces vs no faces.\n",
    "\n",
    "(2) Classifier will learn by extracting features. \n",
    "\n",
    "(3) Cascading works by having the fastest filtering classifiers classify first to weed out the most obvious. We will cascade to slow but precise classifiers that can determine for sure whether or not something is a face and <b> outputs the bounding box. <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"face.jpeg\", 1)\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# for a classifier, we want to turn image into grayscale.\n",
    "\n",
    "path = \"haarscascade_frontalface_default.xml\"\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(path)\n",
    "# Loads in xml file and initializes cascade and classifiers. \n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray,scaleFactor = 1.05, minNeighbors = 5, minSize = (40,40))\n",
    "# face_cascade is the object we have just created\n",
    "# scaleFactor - only want faces close to the camera\n",
    "# minNeighbors - sets number of objects detections before considered a face\n",
    "# minSize - minimum size of face that a face can be to be detected. \n",
    "# Return: list of bounding boxes for all faces detected\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "# each face object in our list has an x,y, width, and height variable.\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0) 2)\n",
    "#paramters of rectangle: original image, top left corner, bottom right corner, color, line thickness.\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
